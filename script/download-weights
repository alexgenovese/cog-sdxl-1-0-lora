#!/usr/bin/env python


import os
import sys
import torch
from diffusers import StableDiffusionPipeline
from diffusers import (
    AutoencoderKL,
    DDIMScheduler,
    DDPMScheduler,
    StableDiffusionPipeline,
    UNet2DConditionModel,
)

from transformers import CLIPTextModel, CLIPTokenizer


cache_dir = "sdxl-v1-0-cache"
vae_cache_dir = "sdxl-vae"
os.makedirs(cache_dir, exist_ok=True)
os.makedirs(vae_cache_dir, exist_ok=True)

pipe = StableDiffusionPipeline.from_pretrained(
    "stabilityai/stable-diffusion-xl-base-1.0",
)

pipe.save_pretrained(cache_dir)


pretrained_vae = AutoencoderKL.from_pretrained(
    "stabilityai/sdxl-vae", subfolder=None, revision=None
)
pretrained_vae.save_pretrained(vae_cache_dir)
