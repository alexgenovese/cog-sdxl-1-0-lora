pretrained_model_name_or_path = "C:\\stable-diffusion-webui\\models\\Stable-diffusion\\sd_xl_base_0.9.safetensors"
dataset_config = "C:\\lora\\dataset_config.toml"
sample_prompts = "C:\\lora\\prompt.txt"
output_dir = "C:\\lora\\model"
logging_dir = "C:\\lora\\log"
output_name = "libsp"
train_batch_size = 1
network_dim = 16
network_alpha = 8
max_train_steps = 1620
save_every_n_steps = 162
sample_every_n_steps = 162
optimizer_type = "adafactor"
optimizer_args = [ "scale_parameter=False", "relative_step=False", "warmup_init=False" ]
lr_scheduler_num_cycles = 6
lr_scheduler = "constant_with_warmup"
lr_warmup_steps = 162
network_train_unet_only = true
learning_rate = 0.0005
unet_lr = 0.0005
text_encoder_lr = 0.0001
caption_extension = ".txt"
resolution = "1024,1024"
save_precision = "fp16"
mixed_precision = "fp16"
sample_sampler = "euler_a"
network_module = "networks.lora"
max_token_length = 225
bucket_reso_steps = 32
cache_latents = true
enable_bucket = true
bucket_no_upscale = true
xformers = false
persistent_data_loader_workers = true
gradient_checkpointing = true
cache_text_encoder_outputs = true
no_half_vae = true